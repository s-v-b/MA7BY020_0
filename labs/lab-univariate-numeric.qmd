---
title: 'LAB: Univariate analysis'
date: "`r Sys.time()`"


execute:
  echo: true
  eval: true
  collapse: true


format:
  html:
    output-file: lab-univariate-numeric.html
  pdf:
    output-file: lab-univariate-numeric.pdf

params:
  truc: html
  year: 2024 
  curriculum: "M1 MIDS & MFA"
  university: "Université Paris Cité"
  homepage: "https://stephane-v-boucheron.fr/courses/eda"
  moodle: ""
---





::: {layout="[80,20]"}

::: {#first-column}

- **`r stringr::str_glue('{params$curriculum}')`**
- **`r stringr::str_glue('[{params$university}](https://www.u-paris.fr)')`**
- `r stringr::str_glue("Année {params$year}-{params$year+1}")`
- `r stringr::str_glue("[Course Homepage]({params$homepage})")`  
- `r stringr::str_glue("[Moodle]({params$moodle})")`

::: 

::: {#second-column}
![](/images/UniversiteParis_monogramme_couleur_RVB.png){align="right" style="size:50px;" width=75}
:::

:::


# Univariate numerical samples

```{r setup-packages}
#| warning: false
#| message: false
#| collapse: true

to_be_loaded <- c("tidyverse", 
                  "magrittr",
                  "skimr",
                  "lobstr"
)

for (pck in to_be_loaded) {
  if (!require(pck, character.only = T)) {
    install.packages(pck, repos="http://cran.rstudio.com/")
    stopifnot(require(pck, character.only = T))
  }  
}
```

```{r}
cat(getwd())
```

# Useful links

- [rmarkdown](bookdown.org/yihui/rmarkdown)
- [dplyr](https://gplot2.tidyverse.org)
- [ggplot2](https://ggplot2.tidyverse.org)
- *R Graphic Cookbook*. Winston Chang. O' Reilly.
- [A blog on ggplot object](https://www.data-imaginist.com/2017/Beneath-the-canvas/)
- [`skimr`]()

# Objectives

In Exploratory analysis of tabular data, univariate analysis is the first step. It consists in exploring, summarizing, visualizing columns of a dataset.

In common circumstances, table wrangling is a prerequisite.   

Then, univariate techniques depend on the kind of columns we are facing.


For *numerical* samples/columns, to name a few:

- Boxplots
- Histograms
- Density plots
- CDF
- Quantile functions
- Miscellanea

For categorical samples/columns, we have: 

- Bar plots
- Column plots


# Dataset


> Since 1948, the US Census Bureau  carries out a monthly Current Population Survey, 
collecting data concerning residents aged above 15  from $150 000$ households. 
This survey is one of the most important sources of information concerning the american workforce. Data reported in file `Recensement.txt`  originate from the 2012 census. 

In this lab, we investigate the numerical colums of the dataset.


After downloading, dataset `Recensement` can be found in file `Recensement.csv`.

Choose a loading function  for the format. `Rstudio` IDE provides a valuable helper. 

Load the data into the session environment and call it `df`.

```{r}
#| eval: true
#| echo: true
#| include: false
list.dirs()
list.files()
getwd()
```

::: {.content-visible when-profile="solution"}

::::: {.callout-note title="Solution" collapse="true"}

```{r}
#| mesage: false
#| collapse: true

df <- readr::read_table("../DATA/Recensement.csv")

df %>% 
  glimpse()
```

:::::

:::

# Table wrangling

Which columns should be considered as categorical/factor?

::: {.content-visible when-profile="solution" collapse="true"}

Deciding which variables are categorical sometimes requires judgement. 

Let us attempt to base the decision on a checkable criterion: determine  the number of distinct values in each column, consider those columns with less than 20 distinct values as factors. 

:::

::: {.content-visible when-profile="solution"}

::::: {.callout-note title="solution" collapse="true"}

```{r}
to_be_categorized  <- df %>% 
  summarise(across(everything(), n_distinct)) %>% 
  pivot_longer(cols = everything(), 
               # names_to = "nom_colonne",
               values_to = c("n_levels")) %>% 
  filter(n_levels < 20) %>% 
  arrange(n_levels) 

to_be_categorized

to_be_categorized %>% 
  pull(name)
```

Columns `NB_PERS` and `NB_ENF` have few unique values and nevertheless we could consider them as quantitative. 

:::::

:::

Coerce the relevant columns as factors. 



::: {.content-visible when-profile="solution"}

::::: {.callout-note title="solution" collapse="true"}

We could proceed by iteration over the relevant columns. We 
use `lobstr::...` to monitor the copy on modify process. 

```{r}
lobstr::obj_addr(df)
lobstr::ref(df)

df_copy <- df 

lobstr::ref(df_copy)

for (cl in pull(to_be_categorized,name)) {
  df_copy[[cl]] <- as_factor(df_copy[[cl]])
}

lobstr::obj_addr(df_copy)
foo <- lobstr::ref(df_copy)
```

We will kill several birds with one stone.

`across()` allows us to  pick  the columns to be categorized, to 
apply `as_factor()` to each of them, and to replace the old column 
by the result of `as_factor(....)`  

```{r}
#| collapse: true
#| 
df_cp <- df %>% 
  mutate(across(all_of(pull(to_be_categorized, name)), as_factor))

lobstr::ref(df_cp)

df %>% 
  glimpse()  
```

We could do this using the WET approach 

```{r}
#| eval: false
df_wet <- df %>% 
  mutate(SEXE = as_factor(SEXE), 
         SYNDICAT = as_factor(SYNDICAT), 
         REGION = as_factor(REGION), 
         STAT_MARI = as_factor(STAT_MARI), 
         NB_ENF = as_factor(NB_ENF), 
         NB_PERS = as_factor(NB_PERS), 
         CATEGORIE = as_factor(CATEGORIE),
         NIV_ETUDES = as_factor(NIV_ETUDES), 
         REV_FOYER = as_factor(REV_FOYER)
  ) 

df_wet %>% 
  glimpse()
```


{{< fa hand-point-right >}} Compare `pull`  and `pluck`

:::::

:::


# Search for missing data  (optional)

Check whether some columns contain missing data (use `is.na`).

::: {.callout-tip}

Useful functions:

- `dplyr::summarise_all`
- `tidyr::pivot_longer`
- `dplyr::arrange`

:::

::: {.content-visible when-profile="solution"}

::::: {.callout-note title="solution" collapse="true"}

```{r}
df %>% 
  is.na() %>% 
  as_tibble %>% 
  summarise(across(everything(), sum))  %>%
  knitr::kable()
```

or 

```{r}
df %>% 
  summarise(across(everything(), \(x) sum(is.na(x)))) 
```

or 

```{r}
df %>% 
  summarise(across(everything(), ~ sum(is.na(.)))) 
```

Note the different ways of introduction anonymous functions.

:::::

:::


# Analysis of column `AGE`

## Numerical summary 



::: {.content-visible when-profile="solution"}

::::: {.callout-note title="solution" collapse="false"}

```{r}
df %>% 
    pull(AGE) %>% 
    summary()

sd(df$AGE) ; IQR(df$AGE) ; mad(df$AGE)
```

:::::

:::

Use `skimr::skim()` 


::: {.content-visible when-profile="solution"}

::::: {.callout-note title="solution" collapse="true"}

```{r}
df %>% 
    pluck("AGE") %>% 
    skimr::skim()
```

```{r}
skm <- df %>% 
  skimr::skim(AGE)

class(skm)

attributes(skm)

tibble::as_tibble(skm)
```


:::::

:::


Compare `mean` and `median`, `sd`  and `IQR`. 

Are mean and median systematically related?

::: {.content-visible when-profile="solution" collapse="true"}

::::: {.callout-note title="solution" collapse="true"}

Ask chatgpt.

There is at least one relation between median and mean for square-integrable distributoins:
$$|\text{Median} - \text{Mean}| \leq \text{sd}$$
Lévy's inequality.

:::::

:::

Are standard deviation and IQR systematically related ?

::: {.content-visible when-profile="solution" collapse="true"}

::::: {.callout-note title="solution" collapse="true"}

Ask chatgpt.

Yes. 

:::::

:::

## Boxplots

Draw a boxplot of the Age distribution 

::: {.content-visible when-profile="solution"}

::::: {.callout-note title="solution" collapse="true"}

```{r}
df %>% 
    ggplot() +
    aes(x=1L, y=AGE) +
    geom_boxplot() +
    labs(
        title="Age distribution",
        subtitle = "Census data"
    )
```

:::::

:::

How would you get rid of the useless ticks on the x-axis? 

::: {.content-visible when-profile="solution" collapse="true"}

::::: {.callout-note title="solution" collapse="true"}

Ask chatgpt.

Yes. 

:::::

:::

## Histograms

Plot a _histogram_ of the empirical distribution of the `AGE` column

::: {.content-visible when-profile="solution"}

::::: {.callout-note title="solution" collapse="true"}

```{r}
p <- df %>% 
  ggplot() +
  aes(x=AGE) +
  labs(
    title = "Age distribution",
    subtitle = "Census data",
    x = "Age (Years)",
    y = "Density"
  ) +
  theme_minimal()

  
p +
  geom_histogram(aes(y=after_stat(density)),
                 bins=15,
                 fill="white",
                 color="black") +
  labs(
    caption = "Histogram"
  )

```




:::::

:::



Try different values for the `bins` parameter of `geom_histogram()`

## Density estimates

Plot a _density_ estimate of the `AGE` column (use `stat_density`.

::: {.content-visible when-profile="solution"}

::::: {.callout-note title="solution" collapse="true"}

```{r}
p +
  stat_density(
              fill="white",
              color="black") +
  labs(
    caption = "Kernel Density Estimate"
  )
```

:::::

:::


Play with parameters `bw`, `kernel` and `adjust`.

## Overlay the two plots  (histogram and density).

::: {.content-visible when-profile="solution"}

::::: {.callout-note title="solution" collapse="true"}

```{r}
p +
  stat_density(
              fill="white",
              color="black") +
  geom_histogram(aes(y=after_stat(density)),
                 bins=15,
                 fill="white",
                 color="black",
                 alpha=.5) +
  labs(
    caption = "Overlayed Density Estimates"
  )
```

:::::

:::


## ECDF 

Plot the Empirical CDF of the AGE distribution 

::: {.content-visible when-profile="solution"}

::::: {.callout-note title="solution" collapse="true"}

```{r}
p +
    stat_ecdf()  +
    labs(
        caption = "Empirical CDF"
  )
```

:::::

:::


Can you read the quartiles from the ECDF pplot?

::: {.content-visible when-profile="solution" collapse="true"}

::::: {.callout-note title="solution" collapse="true"}

Of course. Yes, we can.

:::::

:::

## Quantile function 


PLot the quantile function of the AGE distribution. 


# Repeat the analysis for `SAL_HOR`

::: {.content-visible when-profile="solution"}

::::: {.callout-note title="solution" collapse="true"}

```{r}
p <- df %>% 
  ggplot() +
  aes(x=SAL_HOR) +
  labs(
    title = "Wage distribution",
    subtitle = "Census data",
    x = "Hourly wage",
    y = "Density"
  ) +
  theme_minimal()

  
p +
  geom_histogram(aes(y=after_stat(density)),
                 bins=15,
                 fill="white",
                 color="black") +
  labs(
    caption = "Histogram"
  )
```

:::::

:::


::: {.content-visible when-profile="solution"}

::::: {.callout-note title="solution" collapse="true"}

```{r}
p +
  stat_density(
              fill="white",
              color="black") +
  geom_histogram(aes(y=after_stat(density)),
                 bins=15,
                 fill="white",
                 color="black",
                 alpha=.5) +
  labs(
    caption = "Overlayed Density Estimates"
  )
```

```{r}
truc <- rlang::expr({fill=alpha("white",.5)})
p <- df %>% 
  ggplot() +
  aes(x=SAL_HOR, y=after_stat(density)) +
  labs(
    title = "Wage distribution",
    subtitle = "Census data",
    x = "Hourly wage",
    y = "Density"
  ) +
  theme_minimal()
```

```{r}
p + 
  stat_density(fill=alpha("grey", 0.5), color="black") +
  geom_histogram(fill=alpha("grey", 0.5), color="black", bins=15) +
  labs(
    caption = "Overlayed Density Estimates"
  )
```



:::::

:::


How could you comply with the DRY principle ?

::: {.content-visible when-profile="solution" collapse="true"}

::::: {.callout-note title="solution" collapse="true"}

This amounts to [programming with `ggplot2`](https://ggplot2-book.org/programming) function. This is not straightforward since `ggplot2` relies on data masking. 

> A major requirement of a good data analysis is flexibility. If your data changes, or you discover something that makes you rethink your basic assumptions, you need to be able to easily change many plots at once. The main inhibitor of flexibility is code duplication. If you have the same plotting statement repeated over and over again, you’ll have to make the same change in many different places. Often just the thought of making all those changes is exhausting! This chapter will help you overcome that problem by showing you how to program with ggplot2.

> To make your code more flexible, you need to reduce duplicated code by writing functions. When you notice you’re doing the same thing over and over again, think about how you might generalise it and turn it into a function. If you’re not that familiar with how functions work in R, you might want to brush up your knowledge at https://adv-r.hadley.nz/functions.html. 

From [Hadley Wickham](https://ggplot2-book.org/programming)

An attempt: 

```{r}
#| file: "../_UTILS/make_biotiful.R"
#| echo: true
#| eval: true

```


```{r}
mp <- df_cp |> 
  make_biotifoul(is.numeric) + 
  theme_minimal()

mp
```

Another attempt

```{r}
#| file: "../_UTILS/my_histo.R"
#| echo: true
#| eval: true
```


```{r}
list_plots <- df_cp |> 
  select(where(is.numeric)) |> 
  colnames() |> 
  map(rlang::parse_expr) |>
  map (\(x) my_histo(df, {{x}}))

patchwork::wrap_plots(list_plots)
```
:::::

:::
